---
pagename: Getting Started
redirect_from:
  - consumer-experience-voice-video-ios-prerequisites.html
  - voice-and-video-for-ios-sdk-beta-getting-started-prerequisites.html
  - consumer-experience-voice-video-ios-cocoa-pods.html
  - voice-and-video-for-ios-sdk-beta-getting-started-installing-the-sdk-with-cocoapods.html
  - consumer-experience-voice-video-ios-manually.html
  - voice-and-video-for-ios-sdk-beta-getting-started-installing-the-sdk-manually.html
  - consumer-experience-voice-video-ios-project-settings.html
  - voice-and-video-for-ios-sdk-beta-getting-started-project-settings.html
  - consumer-experience-voice-video-ios-integration-guide.html
  - voice-and-video-for-ios-sdk-beta-getting-started-integration-guide.html
sitesection: Documents
categoryname: "Rich Messaging"
documentname: Voice & Video for iOS SDK (BETA)
permalink: voice-and-video-for-ios-sdk-beta-getting-started.html
indicator: messaging
---

### Prerequisites

LivePerson Voice & Video is a SDK (_Source Development Kit_) for the **Apple iOS** platform. In order to integrate with us, you need to have an app of your own to which you have full source code access. Basic programming knowledge is required.

#### Dependencies

The SDK requires our LivePerson [**Messaging SDK**](consumer-experience-ios-sdk-overview.html) integrated into your app. Your consumers will always engage in a messaging conversation first, before your agents choose to escalate the conversation to a *Voice*, *Video* or *CoBrowse* session.

#### Supported iOS Versions

| iOS Version | Support |  Limitations |
| ------------- |:-------------:|:-------------|
| 8.x or less | not supported  | - |
| 9.0 + | supported, with limitations | limited call notifications  |
| 10.0 + | supported | - |

#### Supported Devices

  * All **iPhone models starting from iPhone 5s**
  * iPhone 4s/5 are not officially supported, but may work
  * iPads are currently not officially supported, but may work
  * iPods are not supported

#### Supported Programming Languages
Only **native applications** written in the either or both programming languages:

  * **Swift**
  * **Objective-C**

Cross-platform apps using native wrappers (e.g. Cordova) can be made to integrate with voice & video support with some additional setup effort. Remote-app control however is only possible on native UI components (like those generated by _React Native_ or _Titanium_). **Neither are currently officially supported.**

#### Other Features

| Feature | Support | Comment |
| ------------- |:-------------:|:-------------|
| **Bitcode** | (currently) **not** supported | Set **Enable Bitcode** in your Build Settings to **NO** |

### Installing the SDK with CocoaPods

**UNAVAILABLE DURING BETA PHASE, PLEASE CONTACT YOUR ACCOUNT TEAM FOR INSTALLATION GUIDELINES**

We recommend installing the SDK using the _CocoaPods_ dependency manager, as this minimizes integration effort. If you are not yet familiar with CocoaPods, we recommend reading the official guide of [CocoaPods](https://cocoapods.org/about).

#### Step 1: Edit your Podfile
After setting up CocoaPods, edit your `Podfile` to look something like this:

```Bash
platform :ios, '10.0'
source 'https://github.com/LivePersonInc/iOSPodSpecs.git'

target 'MyBrandApp' do
  # add the SDK to your app, optionally specify a version '~> 0.1.0'
  pod 'LPCoAppSDK'
  ...
end
```

Make sure your target (here: _MyBrandApp_) matches your actual app build target's name.

#### Step 2: Install Pods

Then type `pod repo update && pod install` to have CocoaPods fetch and install the SDK

CocoaPods will create a `*.xcworkspace` workspace for your XCode project. Use this in future _instead of_ the regular `*.xcodeproj`. Open it and continue with the [Project Settings](consumer-experience-voice-video-ios-project-settings.html) instructions.

### Installing the SDK Manually

We highly recommend integrating our SDK using CocoaPods as [described here](consumer-experience-voice-video-ios-cocoa-pods.html). If this does not fit your needs and you prefer to add the SDK manually follow these steps for your app's __XCode Project__:

#### Step 1: Copy Dependencies

  * Copy the `LPCoAppSDK.framework` to your project's file directory.
  * Next add the `LPCoAppSDK.bundle` contained within the `LPCoAppSDK.framework` to your target's __Build Phases → Copy Bundle Resources__ step

#### Step 2: Link Frameworks
Add the following Frameworks to your build target's __Build Phases → Link Binary With Libraries__ option.

  * `LPCoAppSDK.framework`
  * `GLKit.framework`
  * `VideoToolbox.framework`

![Frameworks](img/link_frameworks.png)

#### Step 3: Adjust Build Settings
Under your target's **Build Settings**, adjust the following:

  * Add the directory containing `LPCoAppSDK.framework` to **Framework Search Path**
  * Add the following line to **Library Search Paths**: 		
	  * *$(FRAMEWORK_SEARCH_PATHS)/LPCoAppSDK.framework/***
  * Add the following flags to your **Other Linker Flags** setting:
      * `-lc++`
      * `-lWebRTC`

**Important**: Ensure that your iOS *Base SDK* is set to *9.0* or higher.

Now continue with the [Project Settings](consumer-experience-voice-video-ios-project-settings.html)

### Project Settings

These settings must be adjusted in your XCode project.

  1. [Bitcode Compilation](#bitcode-compilation)
  2. [VoIP Background Mode](#voip-background-mode)
  3. [Privacy Info (iOS 10)](#voip-support)
  4. [Ring Sound](#ring-sound)

#### Bitcode Compilation
Currently the SDK does not support **Bitcode Compilation**. In your `Build Settings` choose:

   * __Enabled Bitcode__ : **NO**

#### VoIP Support
In the app `Capabilities` section, enable **`Background Mode`**, and check the following options:

  * [x] _Audio, AirPlay and Picture in Picture_
  * [x] _Voice over IP_
  * [x] _Remote notifications_

![Capabilities](img/capabilities_voip.png)

Your app will now be able to receive background calls and continue voice conversations while the app is running in the background.

#### Privacy Info (iOS 10)

Starting from iOS 10, you are required to provide a description of why you need access to the **Microphone** and **Camera**. This is **essential**, as otherwise your app may crash.

Please add the following keys to your app's `Info.plist`:

| Key | Type | Value |
| ------------- |:-------------:|:-------------:|
|  **NSMicrophoneUsageDescription** (Privacy - Microphone Usage Description) | String  | Needed for voice calls |
|  **NSCameraUsageDescription** (Privacy - Camera Usage Description) | String  | Needed for video calls  |

![Settings Privacy](img/settings_privacy.png)

If you wish to localize the user message, create a *localized* file called `InfoPlist.strings` and add translations like this:

```
NSMicrophoneUsageDescription = "Allow for voice calls";
NSCameraUsageDescription = "Allow for video calls";
```

Also set the key __`Localized resources can be mixed`__ in your `Info.plist` to `YES`

For a complete documentation see: [Apple Tech FAQ](https://developer.apple.com/library/content/qa/qa1937/_index.html)
& [Info.plist HowTo](https://developer.apple.com/library/content/documentation/General/Reference/InfoPlistKeyReference/Articles/AboutInformationPropertyListFiles.html#//apple_ref/doc/uid/TP40009254-102276)

#### Ring Sound

To add a ring sound for Push-Calls do either of the following:

  * Create a new sound file named `ring.caf` and add to your project
  * Copy the file `ring.caf` file from our Sample App project into your app's project

Either way make sure it's included in the bundle resources of your app's target. **Hint:** `caf` files are optimized audio files for iOS. You can convert any `aiff` file using the command below:

`afconvert -v -f 'caff' -d aac -s 1 -b 192000 MySource.aif MyOutput.caf`

### Integration into App

Before you continue, make sure you have completed the steps detailed in either:

   * [CocoaPods Installation](consumer-experience-voice-video-ios-cocoa-pods.html) or
   * [Manual Installation](consumer-experience-voice-video-ios-manually.html)

**AND** adjusted your [Project Settings](consumer-experience-voice-video-ios-project-settings.html)

#### Step 1: Header Includes
If you are using a **Swift** project, add this to your app's **Bridging-Header**:

```Header
#import <LPCoAppSDK/LPCoApp.h>
```

**Note:** If you do not have a bridging header yet, simply create a new Objective-C file in your project. XCode will ask to create a briding header for you. For **Objective-C** projects, you can directly import the header in your *.m* file.

#### Step 2: Code Calls

Add the following to your *AppDelegate*'s `application:didFinishLaunchingWithOptions` function:

```swift
func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -> Bool {
    // ... do your regular app setup here

    if #available(iOS 9, *) { // setup & register for push calls
        LPCoApp.initSDK()
        LPCoApp.shared().register { token in
            LPMessagingSDK.instance.registerVoipPushNotifications(token: token!)
        }
    }
}
```

This is *all that is needed* to use the the SDK.

#### Optional: LP Messaging SDK - Integration

To allow users to return to the messaging conversation from within a Voice/Video session, complete the following steps:

* Add the `LPCoAppDelegate` interface to one of your app's active view controllers
* Set itself as delegate
* Implement a callback function:

```swift
class YourViewController: UIViewController,LPCoAppDelegate {
    override func viewDidLoad() {
        LPCoApp.shared().delegate = self;
    }
    func LPCoAppShowMessagingConversation() {
        LPMessagingSDK.instance.showConversation(...)
        // push conversation view controller (see Messaging SDK documentation)
    }
}
```

Now, whenever users tap on the messaging icon, your callback will be executed, returning them to their original conversation.
